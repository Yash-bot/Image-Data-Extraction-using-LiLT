# -*- coding: utf-8 -*-
"""inference_used_api_azure.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WYz2fjrEz7Wm6ErNjZCjnM_mtsPEHGs1

# Import
"""

# prompt: mount drive

from google.colab import drive
drive.mount('/content/drive')

!unzip /content/drive/MyDrive/azure/dataset.zip

!pip install azure-ai-formrecognizer
from azure.core.credentials import AzureKeyCredential
from azure.ai.formrecognizer import DocumentAnalysisClient
import sys
import os
import json
sys.path.append("api/")

from model_prediction import model_prediction
from azure_ocr.prepare_model_inputs import prepare_model_inputs,read_text_from_image
from azure_ocr.post_process import post_process
from config import draw_boxes, labels

import os
from io import BytesIO
import json
import math
from PIL import Image

!pip install fuzzywuzzy
import os
import json
import matplotlib.pyplot as plt
import shutil
import time
from glob import glob
import pandas as pd
from fuzzywuzzy import fuzz
from PIL import Image, ImageOps

!unzip /content/drawn_images_test.zip

"""# Predictions"""



doc_type_mapping = {
    'Account Number:': 'Account_no',
    'IFSC Code': 'IFSC_code',
    'Name': 'Name',
    'Amount': 'Amount',
    'Sign': 'Sign'
}

def get_document_type(extracted_data):
    document_keys = [doc for doc in extracted_data if doc in doc_type_mapping]
    if len(document_keys) == 1:
        return doc_type_mapping[document_keys[0]]
    elif len(document_keys) > 1:
        return f"Couldn't classify the document as there are more than one key found in the extracted data"
    else:
        return "Couldn't classify the document as there is no valid key found in the extracted data"

ocr_dir = "./api/azure_ocr_dir"

def info_extraction_viz(image_path, draw=True):
    basename = os.path.basename(image_path)
    basename_wto_ext, _ = os.path.splitext(basename)
    image = Image.open(image_path)
    image = ImageOps.exif_transpose(image)  # Correct orientation based on EXIF
    image = image.convert('RGB')  # Standardize on RGB color space
    ocr_data, rotated_img, tokens, bboxes = prepare_model_inputs(image, basename_wto_ext)
    predictions, confidences, _  = model_prediction(rotated_img, tokens, bboxes)
    extracted_data = post_process(ocr_data, predictions, confidences)
    if draw:
        img = draw_boxes(rotated_img, bboxes, predictions)
        plt.imshow(img)
        plt.axis('off')
        plt.show()
        img.save(f'/content/data/prediction_drawn/{basename}')
    return extracted_data

info_extraction_viz('data/clean_images/Cheque 083660.png')

image_dir = 'data/drawn_images_val'
all_results=[]
for filename in os.listdir(image_dir):
    if filename.endswith('.png'):  # Assuming your images are PNGs
        image_path = os.path.join(image_dir, filename)
        results = info_extraction_viz(image_path, draw=True)
        if results:
            for key, val in results.items():
                print(key, end=":")
                print(val)
            results_copy = results.copy()
            all_results.append({"filename":filename,"data":results_copy})
        print('----------------------------------------------------------------')

all_results

# prompt: remove , and - and /- from amount label

for result in all_results:
    data = result["data"]
    if "Amount" in data:
        amount = data["Amount"]
        amount = amount.replace(",", "")
        amount = amount.replace("-", "")
        amount = amount.replace("/", "")
        data["Amount"] = amount

all_results

# prompt: all_results into json

with open('all_results.json', 'w') as f:
    json.dump(all_results, f)

image_dir = '/content/data/drawn_images_test'
all_results1=[]
for filename in os.listdir(image_dir):
    if filename.endswith('.png'):  # Assuming your images are PNGs
        image_path = os.path.join(image_dir, filename)
        results1 = info_extraction_viz(image_path, draw=True)
        if results1:
            for key, val in results1.items():
                print(key, end=":")
                print(val)
            results1_copy = results1.copy()
            all_results1.append({"filename":filename,'data':results1_copy})
        print('----------------------------------------------------------------')

for result1 in all_results1:
    data = result1["data"]
    if "Amount" in data:
        amount = data["Amount"]
        amount = amount.replace(",", "")
        amount = amount.replace("-", "")
        amount = amount.replace("/", "")
        data["Amount"] = amount

# prompt: all_results into json

with open('all_results1.json', 'w') as f:
    json.dump(all_results1, f)

with open("/content/val_results.json") as f:
    val_data = json.load(f)

with open("/content/test_results.json") as f:
    test_data = json.load(f)

comine_data = val_data + test_data

print(len(comine_data))

comine_data

with open('gt_data.json', 'w') as f:
    json.dump(comine_data, f)

"""# Load GT"""

with open("gt_data.json") as f:
    gt_data = json.load(f)

gt_data

"""# Validation samples"""

# prompt: convert gt_data into dictionary

gt_data_dict = {item["filename"]: item["data"] for item in gt_data}

gt_data_dict

def clean_amount(amount):
    amount = amount.replace(",", "")
    amount = amount.replace("-", "")
    amount = amount.replace("/", "")
    amount = amount.replace("₹", "")
    amount = amount.replace("\n", "")
    amount = amount.replace(" ", "")
    return amount

def clean_ifsc(IFSC_code):
    IFSC_code = IFSC_code.replace("-", "")
    IFSC_code = IFSC_code.replace("\nSAPPM", "")
    return IFSC_code

def clean_account_no(account_no):
    account_no = account_no.replace(":", "")
    account_no = account_no.replace("\n", "")
    account_no = account_no.replace("ANK500015048⑆", "")
    account_no = account_no.split()[0]
    return account_no



# time_lst = []
final_data = []
issues_files = []
failed_items = []

for filename, corrected_item in gt_data_dict.items():
    try:
        image_path = f'data/clean_images/{filename}'
        print(image_path)
        time_start = time.time()
        # plt.imshow(Image.open(image_path))
        # plt.show()

        results = info_extraction_viz(image_path, draw=False)

        end_start = time.time()

        corrected_item_keys = corrected_item.keys()
        results_keys = results.keys()

        set1 = set(corrected_item_keys)- set(results_keys)
        print(set1)
        if set1:
            print("Above Key(s) are missing the predictions")
            issues_files.append(image_path)


        set2 = set(results_keys)- set(corrected_item_keys)
        print(set2)
        if set2:
            print("Above keys are not present in the document")
            if image_path not in issues_files:
                issues_files.append(image_path)

        line_data = corrected_item.copy()
        line_data['filename'] = filename

        for label in labels:
            if label in corrected_item:
                del line_data[label]
                new_label = f"{label}_gt"
                print(f"\033[1m{label}:\033[0m")
                corr_val = str(corrected_item[label])
                try:

                    pred = str(results[label])
                    if label == 'Amount':
                        pred = clean_amount(pred)
                    if label == 'Account_no':
                        pred = clean_account_no(pred)
                    if label == 'IFSC_code':
                        pred = clean_ifsc(pred)
                    print(corr_val)
                    print('-')
                    print(pred)
                    match_perce = fuzz.ratio(pred, corr_val)
                    print(match_perce)
                except:
                    match_perce = 0
                    pred = None

                line_data[new_label] = corr_val
                new_label = f"{label}_pred"
                line_data[new_label] = pred
                line_data[f"{label}_match"] = match_perce
                print('********************************')
        final_data.append(line_data)

    except Exception as e:
        print(e)
        failed_items.append(filename)

    print(f"{'*' * 25}End{'*' * 25}")

df = pd.DataFrame(final_data)
df.to_excel('final_data.xlsx')
df

labels_match = [x for x in df.columns if '_match' in x]

df_match = df[labels_match]

df_acc = df_match.mean()
df_acc

df_acc.mean()

labels_match

# prompt: zip api folde

!zip -r api.zip api

!zip -r data.zip data

